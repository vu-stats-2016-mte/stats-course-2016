---
title: "Statistical Methods - Assignment 4"
author: "Michel Mooiweer (1866761) Thomas Webbers (2560695) Eirik Kultorp (2544992)"
date: "December 2016"
output: pdf_document
urlcolor: "blue"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn=-1)
```

# Theoretical exercises

## 4.1

- $H_0 : \rho = 0$\
  $H_a : \rho > 0$
- $\alpha = 0.01$
- Test Statistic: $r$
- Critical value from table A-6 for n = 40 and $\alpha=0.01$:
  $0.402$
- Observed value: $0.876$
- Because our observed value is > the critical value we reject the null hypthesis
- There does seem to be a linear correlation between the before and after weights
- The r value shows that there is a correlation between joining and weight loss, but it does not prove that this effect is caused by weight watchers

   
## 4.2 

- $H_0 :$ The frequencies of tire guesses are uniformly distributed \
  $H_a :$ The Frequencies of tire guesses are not uniformly distributed
- $\alpha =0.05$
- Test statistic: \[ X^2 = \sum_{i= 1}^k\frac{(o_{i}- E_{i})^2}{E_{i{}}}\]
  which has a $X^2$ distribution with $k-1 = 3$ degrees of freedom under the null hypothesis
  
- Observed value: $X^2$ = 4.6
- Critical value is 7.815 (Triola A-4)
- Becuase 4.6 < 7.815 we can not reject the null hypotheses that the frequencies are uniformly distributed
- This means that if all 4 students guess they have a 1*.25^3 =0.016 chane to all guess the same tire.

# R-Exercises

## 4.3

### a)

```{r 4.3a, echo=F}
dat=matrix(as.numeric(as.matrix(read.table("crimemale.txt"))[2:19,]),ncol=3)
age=dat[,1]
income=dat[,2]
crimes=dat[,3]

investigate_linear_correlation <- function(v1,v2,xlab,ylab){
  
  plot(v1,v2,xlab=xlab,ylab=ylab)
  corr=cor(v1,v2)
  print(paste("Correlation: (",xlab,",",ylab,")",corr))
  corr=abs(corr)
  
  # TODO adjust these thresholds based on statistical standards (if they exist) 
  
  if (corr<0.7) w ="unlikely"
  else if (corr<0.8) w = "plausible"
  else w="likely"
  print(paste("Linear correlation seems",w))
}

investigate_linear_correlation(age,crimes,"age","crimes")

```

### b)

```{r 4.3b, echo=F}
investigate_linear_correlation(income,crimes,"income","crimes")
```

### c)

```{r 4.3c, echo=F}
lmres = lm(crimes ~ income)
summary(lmres)
print(paste("Intercept =",lmres$coefficients[1]))
print(paste("Slope =",lmres$coefficients[2]))
plot(income,crimes,xlab="Income",ylab="Crimes")
abline(lmres$coefficients, col='red')
```

### d)

- $H_0 : \beta_1 = 0$, $H_a : \beta_1 \neq 0$
- Significance level $\alpha = .05$
- Test statistic: \[T_\beta = b_1/s_{b_1}\]\
  has a t-distribution with df = n-2 = 16 under $H_0$
- Observed value:

```{r 4.3d, echo=F}
unname(lmres$coefficients[2]/0.05527)
```

- Critical values: two-tailed test and $\alpha = 0.05$ so $-t_{16,0.025}$ and $t_{16,0.025}$ i.e. -2.120 and 2.120

- Since 5.181 > 2.120 we reject $H_0$

- There is sufficient evidence to warrant a rejection of the claim that there is no linear relationship between income and crime

### e)

Requirements for testing linearity:
- Independence: (difficult to check)
- Normal distribution of residuals
- Fixed standard deviation

```{r 4.3e, echo=F}
par(mfrow=c(1,2))
qqnorm(lmres$res, main = "Normal Q-Q plot of residuals")
plot(income, lmres$res, ylab="Residuals", main="Residual plot")
```
\
\

(Visusally)
The residual plot shows no obvious pattern\
The Q-Q plot seems to approach normal distribution

So the requirements are met.

## 4.4

### a)

$E_9 = 0.046 * \text{total number of files} =$

```{r 4.4a, echo=F}
sum(c(45,32,18,12,9,3,13,9,9))*0.046
```

### b)
- $H_0 = \text{the observed leading digits follow Benford's law }$\
  $H_a= \text{the digits do not follow Benford's law}$
- Significance level: $\ \alpha = 5\%\ $
- Test statistic: \[ X^2 = \sum_{i= 1}^k\frac{(o_{i}- E_{i})^2}{E_{i{}}}\]
  which has a $X^2$ distribution with $k-1$ degrees of freedom under the null hypothesis
- Observed value($\ X^2$) and P-value:

```{r 4.4b, echo=F}
expected <- c(0.301,0.176,0.125,0.097,0.079,0.067,0.058,0.051,0.046)
observed <-c(45,32,18,12,9,3,13,9,9)
chisq.test(observed, p=expected)
```
- With a significance level of 0.05 we do not have sufficient evidence to reject the null hypothesis and say the digits do not follow Benford's law

## 4.5

### a)

Because we are interested in if each 'subgroup' (which contain the result against one person) follow the same distribution of win, loss, draw we do a test of homeogenity.

- $\ H_0 = \text{andy performs equally well against all opponents}$\
- $\ H_a =\text{andy does not perform equally well against all opponents}$\
```{r 4.5a, echo=F}

```


### b)

- For hypotheses see 4.5a)
- Significance level: $\ \alpha = 5\%\ $
- Test statistic: \[ X^2 = \sum_{i,j}\frac{(o_{ij}- E_{ij})^2}{E_{ij{}}}\]
  which has a $X^2$ distribution with $(rows-1)(columns-1)$ degrees of freedom under the null hypothesis
- Observed value($\ X^2$) and P-value:

```{r 4.5b, echo=F}
result <- matrix(c(179,96,52,39,47,17,13,15,57,36,18,15), ncol = 3)
colnames(result) <-  c('won', 'lost', 'draw')
rownames(result) <- c('Bob', 'Cecilia', 'David', 'Emma')
chisq.test(result)
```
- Because the p value is not below our significance level we can not reject the null hypothesis. Andy might perform equally well against all opponents


### c)

If they play 69 games he is expected to win:

```{r 4.5c, echo=F}
round(chisq.test(result)$exp['Emma', 'won'],3)
```

# Appendix

## 4.3.a

```{r eval=FALSE, ref.label="4.3a"}
```

## 4.3.b

```{r eval=FALSE, ref.label="4.3b"}
```

## 4.3.c

```{r eval=FALSE, ref.label="4.3c"}
```

## 4.3.d

```{r eval=FALSE, ref.label="4.3d"}
```

## 4.3.e

```{r eval=FALSE, ref.label="4.3e"}
```

## 4.4.a

```{r eval=FALSE, ref.label="4.4a"}
```

## 4.4.b

```{r eval=FALSE, ref.label="4.4b"}
```

## 4.5.a

```{r eval=FALSE, ref.label="4.5a"}
```

## 4.5.b

```{r eval=FALSE, ref.label="4.5b"}
```

## 4.5.c

```{r eval=FALSE, ref.label="4.5c"}
```
